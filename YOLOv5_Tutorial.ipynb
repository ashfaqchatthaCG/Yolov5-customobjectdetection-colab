{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "<br>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> ðŸš€ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://discord.gg/n6cFeSPZdD\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e413b9bc-6dc5-4aec-c9a4-d048cd015379"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"fsONItcf1hfpiPVIYf74\")\n",
        "project = rf.workspace(\"alex-hyams-cosqx\").project(\"cash-counter\")\n",
        "dataset = project.version(11).download(\"yolov5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbs3f_1uyzH_",
        "outputId": "ef111c4a-f082-4cb7-a538-1114c42a6524"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (8.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.15)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=7b46e29370a6b8136078024552e35f63ff83a6b55cd32bad284359272e789e8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.0.9 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Cash-Counter-11 to yolov5pytorch: 98% [122511360 / 124339505] bytes"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Cash-Counter-11 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6118/6118 [00:01<00:00, 3674.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights  runs/train/exp3/weights/best.pt --include tflite --img 640"
      ],
      "metadata": {
        "id": "TwysBfCUdjf-",
        "outputId": "c0653ae7-cdf3-4f97-a7ae-30e822ebb1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['runs/train/exp3/weights/best.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.11 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/train/exp3/weights/best.pt with output shape (1, 25200, 15) (13.8 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2023-06-08 19:39:35.326108: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     115200      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     656128      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     131328      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 15),     40455       ['tfc3_5[0][0]',                 \n",
            "                                )                                 'tfc3_6[0][0]',                 \n",
            "                                                                  'tfc3_7[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,095\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,095\n",
            "__________________________________________________________________________________________________\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 9.5s, saved as runs/train/exp3/weights/best_saved_model (27.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "WARNING:absl:Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 268). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 56.2s, saved as runs/train/exp3/weights/best-fp16.tflite (13.5 MB)\n",
            "\n",
            "Export complete (66.6s)\n",
            "Results saved to \u001b[1m/content/yolov5/runs/train/exp3/weights\u001b[0m\n",
            "Detect:          python detect.py --weights runs/train/exp3/weights/best-fp16.tflite \n",
            "Validate:        python val.py --weights runs/train/exp3/weights/best-fp16.tflite \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/exp3/weights/best-fp16.tflite')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pErmytZZeqgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp3/weights/best-fp16.tflite --img 640 --conf 0.25 --source /content/yolov5/Cash-Counter-11/test/images"
      ],
      "metadata": {
        "id": "1WvSNuzRdhsw",
        "outputId": "6d48a55c-c70f-4f58-fc73-55207e943fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp3/weights/best-fp16.tflite'], source=/content/yolov5/Cash-Counter-11/test/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading runs/train/exp3/weights/best-fp16.tflite for TensorFlow Lite inference...\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "image 1/131 /content/yolov5/Cash-Counter-11/test/images/004__5-Cents_usa_jpg.rf.d130db062bc923876a040ab5fbf5b9aa.jpg: 640x640 1 car, 303.6ms\n",
            "image 2/131 /content/yolov5/Cash-Counter-11/test/images/005__1-4-Dollar_usa_jpg.rf.b09a6221d5ce4c0458a433992f3394b5.jpg: 640x640 1 motorcycle, 268.6ms\n",
            "image 3/131 /content/yolov5/Cash-Counter-11/test/images/008__1-Cent_usa_jpg.rf.9f22b707346ad7d7b6f7b9ddb98c1441.jpg: 640x640 1 bicycle, 245.7ms\n",
            "image 4/131 /content/yolov5/Cash-Counter-11/test/images/009__1-Dime_usa_jpg.rf.82c027c8fd19b5bd2f5760970c212f1a.jpg: 640x640 1 person, 242.8ms\n",
            "image 5/131 /content/yolov5/Cash-Counter-11/test/images/012__1-4-Dollar_usa_jpg.rf.d21f3790043003cb788bc91b7c3f17e4.jpg: 640x640 2 motorcycles, 241.8ms\n",
            "image 6/131 /content/yolov5/Cash-Counter-11/test/images/015__1-Dime_usa_jpg.rf.fb21f2b31963eab5f4ca8afe4f839b04.jpg: 640x640 1 bicycle, 254.2ms\n",
            "image 7/131 /content/yolov5/Cash-Counter-11/test/images/016__1-Dime_usa_jpg.rf.761dfa09173af8ea5044826a69c65015.jpg: 640x640 1 person, 1 bicycle, 255.3ms\n",
            "image 8/131 /content/yolov5/Cash-Counter-11/test/images/017__1-4-Dollar_usa_jpg.rf.3c1c43db480d0e078377fbff829033be.jpg: 640x640 1 bicycle, 247.6ms\n",
            "image 9/131 /content/yolov5/Cash-Counter-11/test/images/029__1-4-Dollar_usa_jpg.rf.465b09946bec5faa5ed70f38dc114db1.jpg: 640x640 1 motorcycle, 244.6ms\n",
            "image 10/131 /content/yolov5/Cash-Counter-11/test/images/031__1-Cent_usa_jpg.rf.16b1230b3551278669624ab1c44d1e91.jpg: 640x640 1 car, 380.1ms\n",
            "image 11/131 /content/yolov5/Cash-Counter-11/test/images/031__5-Cents_usa_jpg.rf.1cc85b84a772494d24b4cd78629c462c.jpg: 640x640 1 bicycle, 397.2ms\n",
            "image 12/131 /content/yolov5/Cash-Counter-11/test/images/12E63DB3-5DE6-4359-8813-C771C7EBB630.rf.c79098b2b0d8a09decd09d26bfc0815e.jpg: 640x640 (no detections), 409.9ms\n",
            "image 13/131 /content/yolov5/Cash-Counter-11/test/images/14C0C6CA-2E3A-442C-B5B4-ADC1FF8CE149.rf.d4a32c8326f8ebcffe758b26343a8e61.jpg: 640x640 (no detections), 391.2ms\n",
            "image 14/131 /content/yolov5/Cash-Counter-11/test/images/190A7B52-9631-4278-B5BC-4609794002F4.rf.4404baa9824674dc2f1d8a1fafee4a06.jpg: 640x640 33 cars, 373.8ms\n",
            "image 15/131 /content/yolov5/Cash-Counter-11/test/images/1C472421-46BD-49F3-B26B-9EBB38191F4B.rf.1baaa4927bfc6b620fcb5f1a3c6c1202.jpg: 640x640 (no detections), 398.2ms\n",
            "image 16/131 /content/yolov5/Cash-Counter-11/test/images/20220515_210913_jpg.rf.a437080a2f19232fee3c078d1f509512.jpg: 640x640 2 persons, 1 bicycle, 2 cars, 7 motorcycles, 388.6ms\n",
            "image 17/131 /content/yolov5/Cash-Counter-11/test/images/214D4ED1-D2D5-4107-9731-2DD0587674A3.rf.6fd8984e6c9e139102b0396e12890654.jpg: 640x640 (no detections), 409.3ms\n",
            "image 18/131 /content/yolov5/Cash-Counter-11/test/images/2366AA68-DAEB-4C51-9232-7369F923E169.rf.04d2c57ee2dd801bc276785e7b36b72f.jpg: 640x640 (no detections), 374.2ms\n",
            "image 19/131 /content/yolov5/Cash-Counter-11/test/images/24AE1633-B0B6-4484-A3D8-BB4ADD9E0929.rf.935c76606a712dfb876ff9138c859a5c.jpg: 640x640 (no detections), 268.5ms\n",
            "image 20/131 /content/yolov5/Cash-Counter-11/test/images/25BE9715-7A58-4757-AED2-C8416063A401.rf.ed2be79a1ddd712eb64fc9eb58df909c.jpg: 640x640 (no detections), 247.7ms\n",
            "image 21/131 /content/yolov5/Cash-Counter-11/test/images/2_jpg.rf.ff9c1f06d9570d76fcd562fca4e21694.jpg: 640x640 1 person, 1 bicycle, 1 car, 1 motorcycle, 260.0ms\n",
            "image 22/131 /content/yolov5/Cash-Counter-11/test/images/337C8716-DB70-4215-A93F-D196E222139C.rf.3d4d8879d61b0c5d3c793465e56393d6.jpg: 640x640 (no detections), 256.0ms\n",
            "image 23/131 /content/yolov5/Cash-Counter-11/test/images/37EF6C87-3303-4FE3-91A6-7C564D8CB951.rf.8ea771368284203f50fe715aa7a487e1.jpg: 640x640 (no detections), 265.8ms\n",
            "image 24/131 /content/yolov5/Cash-Counter-11/test/images/41E6B615-BDD5-4BEB-B252-D070D67A27EB.rf.01a938df7dad8772cf765929b9ed3911.jpg: 640x640 (no detections), 270.4ms\n",
            "image 25/131 /content/yolov5/Cash-Counter-11/test/images/445A03D2-DC26-4529-80C0-CCC4E010C82C.rf.7f75b48d0f32fd5adbe5211905191008.jpg: 640x640 (no detections), 258.7ms\n",
            "image 26/131 /content/yolov5/Cash-Counter-11/test/images/454E7171-FCA2-4D69-A0D8-119A6FCE4377.rf.ad557350c156e236ff9ef27ece9f9b1d.jpg: 640x640 (no detections), 270.8ms\n",
            "image 27/131 /content/yolov5/Cash-Counter-11/test/images/47355F82-6C9B-43F4-8A9E-2E53BAD4D129.rf.4dbf8766014a670bfccd7d42e02038cd.jpg: 640x640 (no detections), 246.7ms\n",
            "image 28/131 /content/yolov5/Cash-Counter-11/test/images/4BEB803A-B59F-484E-BFAF-9B93EE66694B.rf.d97f59aa0fe450e3a72babe49509cdd8.jpg: 640x640 (no detections), 255.4ms\n",
            "image 29/131 /content/yolov5/Cash-Counter-11/test/images/4EC69102-2C79-49EB-87B3-40AF49EAEA5A.rf.b5eaf06cc533f821451680bd6cb4a6c2.jpg: 640x640 (no detections), 243.3ms\n",
            "image 30/131 /content/yolov5/Cash-Counter-11/test/images/4_jpg.rf.cf6e93e6366872279889de7553cbd87c.jpg: 640x640 1 person, 7 bicycles, 5 cars, 254.3ms\n",
            "image 31/131 /content/yolov5/Cash-Counter-11/test/images/537E232F-58C9-49DA-B831-03BC2A0306B0.rf.22362157c032bbd9dfd667dbb4c1ec01.jpg: 640x640 (no detections), 250.1ms\n",
            "image 32/131 /content/yolov5/Cash-Counter-11/test/images/60B4AC07-6C65-4612-B46B-0728D3B923BA.rf.3bdb6731515c33e418883f3ae1c92042.jpg: 640x640 (no detections), 296.1ms\n",
            "image 33/131 /content/yolov5/Cash-Counter-11/test/images/6CC2BB66-5417-4B56-BA47-0AE5097B9F85.rf.ec0e073e202b4eed74609d552253c19f.jpg: 640x640 1 truck, 1 traffic light, 249.9ms\n",
            "image 34/131 /content/yolov5/Cash-Counter-11/test/images/6D5D53E4-B683-4996-AE11-8A6A7AB4DF4B.rf.71f06e0755d9543054cb432c3481cedb.jpg: 640x640 (no detections), 249.2ms\n",
            "image 35/131 /content/yolov5/Cash-Counter-11/test/images/6EE050FD-6285-45D6-800D-45C483A50957.rf.376f81b14fecedd1e58099d9bc5e315f.jpg: 640x640 (no detections), 255.4ms\n",
            "image 36/131 /content/yolov5/Cash-Counter-11/test/images/7AA87EDD-A57C-44B0-A4DD-3B5B331B57FF.rf.5d637849b7e1fd45fbdae70d8f53d1c2.jpg: 640x640 2 trucks, 1 boat, 2 traffic lights, 256.7ms\n",
            "image 37/131 /content/yolov5/Cash-Counter-11/test/images/7FE0C68B-5DA7-4409-B692-28923D30390F.rf.723dabb31faaf8107bc0a661bb796760.jpg: 640x640 (no detections), 252.9ms\n",
            "image 38/131 /content/yolov5/Cash-Counter-11/test/images/8CF84A73-8E43-43D6-B4C1-0CDEC07227C6.rf.d6616089d4fc82a3cdb7afbf0ed1a09b.jpg: 640x640 (no detections), 292.8ms\n",
            "image 39/131 /content/yolov5/Cash-Counter-11/test/images/8FBA9D91-2F25-4155-AE79-C14BDE970217.rf.2b8afb3155dd5c89cf06cbf60f1f6a9f.jpg: 640x640 (no detections), 257.5ms\n",
            "image 40/131 /content/yolov5/Cash-Counter-11/test/images/92C96025-8394-45FF-8A68-C5EEE6763CEC.rf.f5655f2960d866ad4b2bd06057d27bee.jpg: 640x640 (no detections), 250.7ms\n",
            "image 41/131 /content/yolov5/Cash-Counter-11/test/images/9CCD2BC8-C162-49F0-BA99-EE3F62DD2967.rf.4638f26524f1630b987b0682a3e24922.jpg: 640x640 (no detections), 245.2ms\n",
            "image 42/131 /content/yolov5/Cash-Counter-11/test/images/9ED27C3F-9403-41FE-B371-B7A510E6DA3E.rf.3148ddfceeaa8d472a99e6e9e9a619cd.jpg: 640x640 1 bus, 2 trucks, 1 boat, 2 traffic lights, 249.8ms\n",
            "image 43/131 /content/yolov5/Cash-Counter-11/test/images/A28B3C73-CCA2-48D8-8897-195C923C5532.rf.3831ec9d93a8181c905b8bfd1d290036.jpg: 640x640 (no detections), 262.1ms\n",
            "image 44/131 /content/yolov5/Cash-Counter-11/test/images/B2368764-D08D-447C-A920-702CC77DCC90.rf.f60478874c6e841a5f2c5d6f0fcf1c53.jpg: 640x640 (no detections), 248.2ms\n",
            "image 45/131 /content/yolov5/Cash-Counter-11/test/images/B40CBA52-D4AB-4506-A6D7-E2577758FF95.rf.5b1c451eebb3556bcd8f69b462a54e77.jpg: 640x640 (no detections), 240.4ms\n",
            "image 46/131 /content/yolov5/Cash-Counter-11/test/images/BDBF7E12-F2B1-4FCA-88B1-134362F33A35.rf.818298b220622308ec53f20b8f66a482.jpg: 640x640 (no detections), 248.6ms\n",
            "image 47/131 /content/yolov5/Cash-Counter-11/test/images/C62860BC-2844-4544-9B6C-12F07098EB41.rf.1e4d76e680abf31538e9a86bb59628c6.jpg: 640x640 (no detections), 251.9ms\n",
            "image 48/131 /content/yolov5/Cash-Counter-11/test/images/C6E98944-1DD7-480C-B749-49E389D96646.rf.adcb7b29f84d30e5730aab1472c8720b.jpg: 640x640 (no detections), 268.0ms\n",
            "image 49/131 /content/yolov5/Cash-Counter-11/test/images/CAFE98D8-7E49-4958-8EB9-F0A2571B4365.rf.cee9434b6bc8c163126b5a3a2f501bcf.jpg: 640x640 (no detections), 256.0ms\n",
            "image 50/131 /content/yolov5/Cash-Counter-11/test/images/CE5FC0CA-E8B4-48D5-811D-1EB47EA026E9.rf.d834318a16bc1cbb456864db9ed2d239.jpg: 640x640 (no detections), 245.3ms\n",
            "image 51/131 /content/yolov5/Cash-Counter-11/test/images/D543D353-374F-4903-B27D-BDCB52B7C028.rf.411ada6f3aedfccd8f0f87905224f656.jpg: 640x640 (no detections), 254.8ms\n",
            "image 52/131 /content/yolov5/Cash-Counter-11/test/images/D700F7EA-82D4-4C36-81B6-396923AD3470.rf.4697d702f2af55fdd6ff12bd1f51f6f3.jpg: 640x640 (no detections), 245.6ms\n",
            "image 53/131 /content/yolov5/Cash-Counter-11/test/images/D70FE378-95B6-4640-8A3E-EB36FE028FCE.rf.45020f364a47362622cf3a20baf088fe.jpg: 640x640 (no detections), 248.2ms\n",
            "image 54/131 /content/yolov5/Cash-Counter-11/test/images/D959B8EF-0A47-4F17-B4F3-8E898E3081E4.rf.516fa2c7247ef433ba56377d5179deaa.jpg: 640x640 (no detections), 259.4ms\n",
            "image 55/131 /content/yolov5/Cash-Counter-11/test/images/DC3AD232-A32F-4623-A32C-3C345CA78885.rf.47cec34985ddc162fbee00e03c0ab92c.jpg: 640x640 (no detections), 251.0ms\n",
            "image 56/131 /content/yolov5/Cash-Counter-11/test/images/EC9A6263-73E1-4D04-A1C0-4D19A1CAAEDC.rf.a63517ff27c10d9442b3dd42b2bf4362.jpg: 640x640 (no detections), 373.3ms\n",
            "image 57/131 /content/yolov5/Cash-Counter-11/test/images/F6665D91-A97F-40C7-939E-0724F56CB61D.rf.1190bd1e3cf3dde47f93d340beceb843.jpg: 640x640 (no detections), 402.7ms\n",
            "image 58/131 /content/yolov5/Cash-Counter-11/test/images/F82A4609-350B-4E73-B2B1-F3A7897A137D.rf.28123a6f5aedef16ea957a4b365709e5.jpg: 640x640 (no detections), 407.9ms\n",
            "image 59/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1901_jpg.rf.ba951e0d0604529329e67a885cbb9fc9.jpg: 640x640 1 traffic light, 414.7ms\n",
            "image 60/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1905_jpg.rf.2be4f1a51018ceff3a15bd075c530671.jpg: 640x640 1 traffic light, 392.5ms\n",
            "image 61/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1908_jpg.rf.203e27d272302fe19931edc5c29b4e77.jpg: 640x640 1 traffic light, 406.2ms\n",
            "image 62/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1920_jpg.rf.3f47c19c7361ffaa4d01a6f365877b89.jpg: 640x640 1 traffic light, 398.6ms\n",
            "image 63/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1931_jpg.rf.6080e808aeec33f6ac7081a766780bf0.jpg: 640x640 1 traffic light, 385.5ms\n",
            "image 64/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1936_jpg.rf.8bb439b5ef4b5304ea14627c65d53c8e.jpg: 640x640 1 traffic light, 376.9ms\n",
            "image 65/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1941_jpg.rf.01d84aafc0209fc035c891a3f35dab20.jpg: 640x640 1 traffic light, 264.3ms\n",
            "image 66/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1951_jpg.rf.226e6ddfd29d9ec236bd723420cf17bb.jpg: 640x640 1 airplane, 364.7ms\n",
            "image 67/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1964_jpg.rf.9a8b1b4bf231fa881b542fb97cda9177.jpg: 640x640 1 airplane, 251.4ms\n",
            "image 68/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2009_jpg.rf.b45f163c2bc35bc9f450bf26479d841f.jpg: 640x640 1 bus, 255.1ms\n",
            "image 69/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2011_jpg.rf.ab8d29a86bca04f3b7178ae523652575.jpg: 640x640 1 bus, 257.1ms\n",
            "image 70/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2019_jpg.rf.63707ea418856af64416dbd05c2e2b2d.jpg: 640x640 1 airplane, 248.6ms\n",
            "image 71/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2020_jpg.rf.77cea6500bb3b1a92897000fbd241c82.jpg: 640x640 1 bus, 245.2ms\n",
            "image 72/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2028_jpg.rf.d2dbd5f3a665d5c1d9559e9a3e204fa0.jpg: 640x640 1 bus, 1 traffic light, 260.2ms\n",
            "image 73/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2029_jpg.rf.28f171d1035d42e14a88b1a1cc7d09f1.jpg: 640x640 1 bus, 249.1ms\n",
            "image 74/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2047_jpg.rf.d4c3d25bc00cb3b4f38f24f45e5c2e60.jpg: 640x640 1 truck, 258.7ms\n",
            "image 75/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2081_jpg.rf.bf3a82a3f17e2a2955b58f6f26ccce32.jpg: 640x640 1 traffic light, 260.6ms\n",
            "image 76/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2087_jpg.rf.1df0dbc5a8fb3644643725177ea111fb.jpg: 640x640 1 bus, 260.2ms\n",
            "image 77/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2094_jpg.rf.3e70f255e403911a57c01204cdce4967.jpg: 640x640 2 trucks, 242.8ms\n",
            "image 78/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2098_jpg.rf.d22a669811757e71d10c361793f0d97d.jpg: 640x640 1 boat, 258.8ms\n",
            "image 79/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-10_jpg.rf.2d34d221c55c8c2a066b3e44e441676d.jpg: 640x640 3 trains, 249.4ms\n",
            "image 80/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-13_jpg.rf.b16a8be1ad32bad45a87621ce897ed36.jpg: 640x640 3 trains, 263.5ms\n",
            "image 81/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-14_jpg.rf.f92e890d37aa3cb2a4ff262692149a39.jpg: 640x640 3 trains, 239.7ms\n",
            "image 82/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-17_jpg.rf.bc51ffd737fa8c48385b8e0e83a0eb51.jpg: 640x640 3 trains, 256.2ms\n",
            "image 83/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-6_jpg.rf.41b733e7d5e3c3cadb9b1e109c971f25.jpg: 640x640 3 trains, 241.6ms\n",
            "image 84/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2154_mp4-3_jpg.rf.2c60a73a22a82a5d19f7e2dd022a6e4f.jpg: 640x640 1 train, 241.0ms\n",
            "image 85/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2154_mp4-6_jpg.rf.0de4783483a6c36c5892701bb7b0ca31.jpg: 640x640 1 train, 254.0ms\n",
            "image 86/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2156_mp4-1_jpg.rf.bb614941b325fdff64a7a8ef2624d26e.jpg: 640x640 1 airplane, 1 traffic light, 248.7ms\n",
            "image 87/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2156_mp4-8_jpg.rf.1d7e867267a830632a8644349c094173.jpg: 640x640 (no detections), 280.4ms\n",
            "image 88/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2161_jpeg_jpg.rf.ef28cd99b87eabbcbef5451b2dae20b9.jpg: 640x640 1 traffic light, 251.0ms\n",
            "image 89/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2177_jpeg_jpg.rf.fb372ef036dcf5160f66f2a9545693af.jpg: 640x640 1 truck, 252.6ms\n",
            "image 90/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2186_jpeg_jpg.rf.129abb76f639fa8c4aa067231649eaff.jpg: 640x640 1 truck, 247.8ms\n",
            "image 91/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2191_jpeg_jpg.rf.5e6cfece1e7645bd769c297397eef710.jpg: 640x640 1 bus, 272.9ms\n",
            "image 92/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2197_jpeg_jpg.rf.038b34bd4fc20e4e32dd0d6c59d4d856.jpg: 640x640 1 bus, 251.6ms\n",
            "image 93/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2204_jpeg_jpg.rf.fe2f4fac6071b68795de01f3a493b403.jpg: 640x640 1 traffic light, 266.1ms\n",
            "image 94/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2228_jpeg_jpg.rf.0285c78d611bbc7ae422454915504469.jpg: 640x640 1 airplane, 249.0ms\n",
            "image 95/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2234_jpeg_jpg.rf.96715f9aadc0a001ff43f36e0bbd7f4b.jpg: 640x640 1 airplane, 248.3ms\n",
            "image 96/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2255_jpeg_jpg.rf.5adab7027aa07ae7c344c257269e624b.jpg: 640x640 1 boat, 247.3ms\n",
            "image 97/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2266_jpeg_jpg.rf.ab04e53ed55c88b3727d5ef805e194e1.jpg: 640x640 1 boat, 243.1ms\n",
            "image 98/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2267_jpeg_jpg.rf.c4fe47363136f619f25cc61df94eebb9.jpg: 640x640 1 boat, 409.7ms\n",
            "image 99/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2284_jpeg_jpg.rf.04556136e99ea762fc80709c0eaabaec.jpg: 640x640 1 airplane, 257.2ms\n",
            "image 100/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2307_jpeg_jpg.rf.d94d73e7e451697254754d5409fceffa.jpg: 640x640 1 bus, 1 truck, 1 traffic light, 502.3ms\n",
            "image 101/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2312_jpeg_jpg.rf.aea7bdda8e324c639bf3e10d022efc09.jpg: 640x640 1 bus, 397.1ms\n",
            "image 102/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2321_jpeg_jpg.rf.fad8623e27a470a12e10e704d7aae517.jpg: 640x640 1 truck, 373.6ms\n",
            "image 103/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2326_jpeg_jpg.rf.ac738904a1dd703e20ff7a94380e5ebe.jpg: 640x640 1 airplane, 395.1ms\n",
            "image 104/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8469_jpg.rf.88faf80acb3c3908a5a1de7af5e3f0c1.jpg: 640x640 8 bicycles, 8 cars, 376.1ms\n",
            "image 105/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8470_jpg.rf.c2359b2eec1b4f2eb860b24e45797cf4.jpg: 640x640 8 bicycles, 8 cars, 378.0ms\n",
            "image 106/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8472_jpg.rf.64d1b3feadd09df1ffea3c84ed0861fc.jpg: 640x640 7 bicycles, 9 cars, 2 motorcycles, 385.7ms\n",
            "image 107/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8475_jpg.rf.d722e746c3d24cf2a247ef39d6d0d8c0.jpg: 640x640 8 bicycles, 8 cars, 400.0ms\n",
            "image 108/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8480_jpg.rf.2e5932e577701b9fc876de30ba7492a9.jpg: 640x640 13 bicycles, 13 cars, 400.6ms\n",
            "image 109/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8482_jpg.rf.84e5bfd7bd3808f150ce879cda579ee3.jpg: 640x640 13 bicycles, 13 cars, 257.8ms\n",
            "image 110/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8483_jpg.rf.df5fff47f5ef50456fb21cc09e8abf94.jpg: 640x640 13 bicycles, 13 cars, 240.7ms\n",
            "image 111/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8485_jpg.rf.f0570e571fa1215577964f8f9024042c.jpg: 640x640 13 bicycles, 13 cars, 237.7ms\n",
            "image 112/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8495_jpg.rf.3089a212f35f8dab42ac0e6de0ff1d24.jpg: 640x640 8 cars, 8 motorcycles, 256.4ms\n",
            "image 113/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8495_jpg.rf.f453cf3c90b09fcdd3929328b0654b4b.jpg: 640x640 8 cars, 8 motorcycles, 247.9ms\n",
            "image 114/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8497_jpg.rf.2013b05faa98a345f7aea608f2ebd66d.jpg: 640x640 8 cars, 8 motorcycles, 250.0ms\n",
            "image 115/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8499_jpg.rf.f136aac8678b6e934c42cf847f8ca3f4.jpg: 640x640 8 cars, 8 motorcycles, 257.5ms\n",
            "image 116/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8505_jpg.rf.114e12ac2cf9e949399568d2111960a1.jpg: 640x640 8 cars, 8 motorcycles, 255.2ms\n",
            "image 117/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8508_jpg.rf.1f4786e7783ce2d16610bd3eacde5642.jpg: 640x640 8 cars, 8 motorcycles, 241.9ms\n",
            "image 118/131 /content/yolov5/Cash-Counter-11/test/images/Photo-on-10-26-21-at-2-33-PM-3_jpg.rf.18e64e41737c6d5e040246ee3d30c97b.jpg: 640x640 (no detections), 260.4ms\n",
            "image 119/131 /content/yolov5/Cash-Counter-11/test/images/Photo-on-10-26-21-at-2-37-PM-2_jpg.rf.29e1155d26d061f904903dc35017a6fc.jpg: 640x640 (no detections), 243.3ms\n",
            "image 120/131 /content/yolov5/Cash-Counter-11/test/images/S10_jpg.rf.b038e6bfd2e8bee8bc6a8a460ab209b3.jpg: 640x640 15 persons, 6 bicycles, 266.8ms\n",
            "image 121/131 /content/yolov5/Cash-Counter-11/test/images/S11_jpg.rf.4ea257a2254eb09dd28464f1161e4603.jpg: 640x640 15 persons, 8 bicycles, 247.0ms\n",
            "image 122/131 /content/yolov5/Cash-Counter-11/test/images/S13_jpg.rf.10f2cc79057ecc91d470e6936e3ffedf.jpg: 640x640 15 persons, 21 cars, 265.0ms\n",
            "image 123/131 /content/yolov5/Cash-Counter-11/test/images/S15_jpg.rf.e474b32ba63a61e489de8eb256e304ae.jpg: 640x640 3 persons, 1 bicycle, 21 cars, 285.2ms\n",
            "image 124/131 /content/yolov5/Cash-Counter-11/test/images/S1_jpg.rf.1a1b2128ae0f19ccfbe5d35649baf7d3.jpg: 640x640 15 bicycles, 262.7ms\n",
            "image 125/131 /content/yolov5/Cash-Counter-11/test/images/S21_jpg.rf.adc22c7b16e9945902a4247d7c224d42.jpg: 640x640 19 persons, 4 bicycles, 15 cars, 251.9ms\n",
            "image 126/131 /content/yolov5/Cash-Counter-11/test/images/S23_jpg.rf.199810dc4acf47b8aec37faabaf435c2.jpg: 640x640 20 persons, 15 bicycles, 15 cars, 253.3ms\n",
            "image 127/131 /content/yolov5/Cash-Counter-11/test/images/S23_jpg.rf.fcf4dd0ad67a2d991967bb4660a32ee0.jpg: 640x640 18 persons, 15 bicycles, 15 cars, 246.5ms\n",
            "image 128/131 /content/yolov5/Cash-Counter-11/test/images/S6_jpg.rf.27f7c270e5acfbdf2ea3781fd637ece1.jpg: 640x640 15 persons, 5 bicycles, 250.8ms\n",
            "image 129/131 /content/yolov5/Cash-Counter-11/test/images/S7_jpg.rf.d9c51f2dcaa30d794f68354d321b3de0.jpg: 640x640 16 persons, 1 bicycle, 242.2ms\n",
            "image 130/131 /content/yolov5/Cash-Counter-11/test/images/S9_jpg.rf.bd96f1160475fd928d87d679c99b9ea9.jpg: 640x640 17 persons, 3 bicycles, 264.3ms\n",
            "image 131/131 /content/yolov5/Cash-Counter-11/test/images/conveyerBoxes-AdobeStock_193267768_mov-10_jpg.rf.f65b8f806082924cbacd0fa8d78c888c.jpg: 640x640 (no detections), 273.0ms\n",
            "Speed: 0.8ms pre-process, 286.1ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp11\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b716ce94-71aa-4ac3-c96a-5fe0d11746ea"
      },
      "source": [
        "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.25 --source /content/yolov5/Cash-Counter-11/test/images"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp3/weights/best.pt'], source=/content/yolov5/Cash-Counter-11/test/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/131 /content/yolov5/Cash-Counter-11/test/images/004__5-Cents_usa_jpg.rf.d130db062bc923876a040ab5fbf5b9aa.jpg: 640x640 1 Penny, 11.6ms\n",
            "image 2/131 /content/yolov5/Cash-Counter-11/test/images/005__1-4-Dollar_usa_jpg.rf.b09a6221d5ce4c0458a433992f3394b5.jpg: 640x640 1 Quarter, 11.6ms\n",
            "image 3/131 /content/yolov5/Cash-Counter-11/test/images/008__1-Cent_usa_jpg.rf.9f22b707346ad7d7b6f7b9ddb98c1441.jpg: 640x640 1 Nickel, 11.6ms\n",
            "image 4/131 /content/yolov5/Cash-Counter-11/test/images/009__1-Dime_usa_jpg.rf.82c027c8fd19b5bd2f5760970c212f1a.jpg: 640x640 1 Dime, 11.6ms\n",
            "image 5/131 /content/yolov5/Cash-Counter-11/test/images/012__1-4-Dollar_usa_jpg.rf.d21f3790043003cb788bc91b7c3f17e4.jpg: 640x640 2 Quarters, 11.6ms\n",
            "image 6/131 /content/yolov5/Cash-Counter-11/test/images/015__1-Dime_usa_jpg.rf.fb21f2b31963eab5f4ca8afe4f839b04.jpg: 640x640 1 Nickel, 11.6ms\n",
            "image 7/131 /content/yolov5/Cash-Counter-11/test/images/016__1-Dime_usa_jpg.rf.761dfa09173af8ea5044826a69c65015.jpg: 640x640 1 Dime, 1 Nickel, 11.6ms\n",
            "image 8/131 /content/yolov5/Cash-Counter-11/test/images/017__1-4-Dollar_usa_jpg.rf.3c1c43db480d0e078377fbff829033be.jpg: 640x640 1 Nickel, 11.6ms\n",
            "image 9/131 /content/yolov5/Cash-Counter-11/test/images/029__1-4-Dollar_usa_jpg.rf.465b09946bec5faa5ed70f38dc114db1.jpg: 640x640 1 Quarter, 11.6ms\n",
            "image 10/131 /content/yolov5/Cash-Counter-11/test/images/031__1-Cent_usa_jpg.rf.16b1230b3551278669624ab1c44d1e91.jpg: 640x640 1 Penny, 11.6ms\n",
            "image 11/131 /content/yolov5/Cash-Counter-11/test/images/031__5-Cents_usa_jpg.rf.1cc85b84a772494d24b4cd78629c462c.jpg: 640x640 1 Nickel, 11.6ms\n",
            "image 12/131 /content/yolov5/Cash-Counter-11/test/images/12E63DB3-5DE6-4359-8813-C771C7EBB630.rf.c79098b2b0d8a09decd09d26bfc0815e.jpg: 640x640 (no detections), 11.6ms\n",
            "image 13/131 /content/yolov5/Cash-Counter-11/test/images/14C0C6CA-2E3A-442C-B5B4-ADC1FF8CE149.rf.d4a32c8326f8ebcffe758b26343a8e61.jpg: 640x640 (no detections), 11.6ms\n",
            "image 14/131 /content/yolov5/Cash-Counter-11/test/images/190A7B52-9631-4278-B5BC-4609794002F4.rf.4404baa9824674dc2f1d8a1fafee4a06.jpg: 640x640 33 Pennys, 11.6ms\n",
            "image 15/131 /content/yolov5/Cash-Counter-11/test/images/1C472421-46BD-49F3-B26B-9EBB38191F4B.rf.1baaa4927bfc6b620fcb5f1a3c6c1202.jpg: 640x640 (no detections), 10.1ms\n",
            "image 16/131 /content/yolov5/Cash-Counter-11/test/images/20220515_210913_jpg.rf.a437080a2f19232fee3c078d1f509512.jpg: 640x640 2 Dimes, 1 Nickel, 2 Pennys, 7 Quarters, 10.1ms\n",
            "image 17/131 /content/yolov5/Cash-Counter-11/test/images/214D4ED1-D2D5-4107-9731-2DD0587674A3.rf.6fd8984e6c9e139102b0396e12890654.jpg: 640x640 (no detections), 10.1ms\n",
            "image 18/131 /content/yolov5/Cash-Counter-11/test/images/2366AA68-DAEB-4C51-9232-7369F923E169.rf.04d2c57ee2dd801bc276785e7b36b72f.jpg: 640x640 (no detections), 10.1ms\n",
            "image 19/131 /content/yolov5/Cash-Counter-11/test/images/24AE1633-B0B6-4484-A3D8-BB4ADD9E0929.rf.935c76606a712dfb876ff9138c859a5c.jpg: 640x640 (no detections), 10.1ms\n",
            "image 20/131 /content/yolov5/Cash-Counter-11/test/images/25BE9715-7A58-4757-AED2-C8416063A401.rf.ed2be79a1ddd712eb64fc9eb58df909c.jpg: 640x640 (no detections), 10.1ms\n",
            "image 21/131 /content/yolov5/Cash-Counter-11/test/images/2_jpg.rf.ff9c1f06d9570d76fcd562fca4e21694.jpg: 640x640 1 Dime, 1 Nickel, 1 Penny, 1 Quarter, 10.1ms\n",
            "image 22/131 /content/yolov5/Cash-Counter-11/test/images/337C8716-DB70-4215-A93F-D196E222139C.rf.3d4d8879d61b0c5d3c793465e56393d6.jpg: 640x640 (no detections), 10.1ms\n",
            "image 23/131 /content/yolov5/Cash-Counter-11/test/images/37EF6C87-3303-4FE3-91A6-7C564D8CB951.rf.8ea771368284203f50fe715aa7a487e1.jpg: 640x640 (no detections), 10.1ms\n",
            "image 24/131 /content/yolov5/Cash-Counter-11/test/images/41E6B615-BDD5-4BEB-B252-D070D67A27EB.rf.01a938df7dad8772cf765929b9ed3911.jpg: 640x640 (no detections), 10.1ms\n",
            "image 25/131 /content/yolov5/Cash-Counter-11/test/images/445A03D2-DC26-4529-80C0-CCC4E010C82C.rf.7f75b48d0f32fd5adbe5211905191008.jpg: 640x640 (no detections), 10.1ms\n",
            "image 26/131 /content/yolov5/Cash-Counter-11/test/images/454E7171-FCA2-4D69-A0D8-119A6FCE4377.rf.ad557350c156e236ff9ef27ece9f9b1d.jpg: 640x640 (no detections), 10.1ms\n",
            "image 27/131 /content/yolov5/Cash-Counter-11/test/images/47355F82-6C9B-43F4-8A9E-2E53BAD4D129.rf.4dbf8766014a670bfccd7d42e02038cd.jpg: 640x640 (no detections), 10.1ms\n",
            "image 28/131 /content/yolov5/Cash-Counter-11/test/images/4BEB803A-B59F-484E-BFAF-9B93EE66694B.rf.d97f59aa0fe450e3a72babe49509cdd8.jpg: 640x640 (no detections), 10.1ms\n",
            "image 29/131 /content/yolov5/Cash-Counter-11/test/images/4EC69102-2C79-49EB-87B3-40AF49EAEA5A.rf.b5eaf06cc533f821451680bd6cb4a6c2.jpg: 640x640 (no detections), 10.1ms\n",
            "image 30/131 /content/yolov5/Cash-Counter-11/test/images/4_jpg.rf.cf6e93e6366872279889de7553cbd87c.jpg: 640x640 1 Dime, 7 Nickels, 5 Pennys, 10.1ms\n",
            "image 31/131 /content/yolov5/Cash-Counter-11/test/images/537E232F-58C9-49DA-B831-03BC2A0306B0.rf.22362157c032bbd9dfd667dbb4c1ec01.jpg: 640x640 (no detections), 9.1ms\n",
            "image 32/131 /content/yolov5/Cash-Counter-11/test/images/60B4AC07-6C65-4612-B46B-0728D3B923BA.rf.3bdb6731515c33e418883f3ae1c92042.jpg: 640x640 (no detections), 9.1ms\n",
            "image 33/131 /content/yolov5/Cash-Counter-11/test/images/6CC2BB66-5417-4B56-BA47-0AE5097B9F85.rf.ec0e073e202b4eed74609d552253c19f.jpg: 640x640 1 one, 1 twenty, 9.1ms\n",
            "image 34/131 /content/yolov5/Cash-Counter-11/test/images/6D5D53E4-B683-4996-AE11-8A6A7AB4DF4B.rf.71f06e0755d9543054cb432c3481cedb.jpg: 640x640 (no detections), 9.1ms\n",
            "image 35/131 /content/yolov5/Cash-Counter-11/test/images/6EE050FD-6285-45D6-800D-45C483A50957.rf.376f81b14fecedd1e58099d9bc5e315f.jpg: 640x640 (no detections), 9.0ms\n",
            "image 36/131 /content/yolov5/Cash-Counter-11/test/images/7AA87EDD-A57C-44B0-A4DD-3B5B331B57FF.rf.5d637849b7e1fd45fbdae70d8f53d1c2.jpg: 640x640 2 ones, 1 ten, 2 twentys, 9.0ms\n",
            "image 37/131 /content/yolov5/Cash-Counter-11/test/images/7FE0C68B-5DA7-4409-B692-28923D30390F.rf.723dabb31faaf8107bc0a661bb796760.jpg: 640x640 (no detections), 9.0ms\n",
            "image 38/131 /content/yolov5/Cash-Counter-11/test/images/8CF84A73-8E43-43D6-B4C1-0CDEC07227C6.rf.d6616089d4fc82a3cdb7afbf0ed1a09b.jpg: 640x640 (no detections), 9.0ms\n",
            "image 39/131 /content/yolov5/Cash-Counter-11/test/images/8FBA9D91-2F25-4155-AE79-C14BDE970217.rf.2b8afb3155dd5c89cf06cbf60f1f6a9f.jpg: 640x640 (no detections), 9.0ms\n",
            "image 40/131 /content/yolov5/Cash-Counter-11/test/images/92C96025-8394-45FF-8A68-C5EEE6763CEC.rf.f5655f2960d866ad4b2bd06057d27bee.jpg: 640x640 (no detections), 8.8ms\n",
            "image 41/131 /content/yolov5/Cash-Counter-11/test/images/9CCD2BC8-C162-49F0-BA99-EE3F62DD2967.rf.4638f26524f1630b987b0682a3e24922.jpg: 640x640 (no detections), 8.8ms\n",
            "image 42/131 /content/yolov5/Cash-Counter-11/test/images/9ED27C3F-9403-41FE-B371-B7A510E6DA3E.rf.3148ddfceeaa8d472a99e6e9e9a619cd.jpg: 640x640 1 five, 2 ones, 1 ten, 2 twentys, 8.8ms\n",
            "image 43/131 /content/yolov5/Cash-Counter-11/test/images/A28B3C73-CCA2-48D8-8897-195C923C5532.rf.3831ec9d93a8181c905b8bfd1d290036.jpg: 640x640 (no detections), 8.8ms\n",
            "image 44/131 /content/yolov5/Cash-Counter-11/test/images/B2368764-D08D-447C-A920-702CC77DCC90.rf.f60478874c6e841a5f2c5d6f0fcf1c53.jpg: 640x640 (no detections), 8.8ms\n",
            "image 45/131 /content/yolov5/Cash-Counter-11/test/images/B40CBA52-D4AB-4506-A6D7-E2577758FF95.rf.5b1c451eebb3556bcd8f69b462a54e77.jpg: 640x640 (no detections), 8.8ms\n",
            "image 46/131 /content/yolov5/Cash-Counter-11/test/images/BDBF7E12-F2B1-4FCA-88B1-134362F33A35.rf.818298b220622308ec53f20b8f66a482.jpg: 640x640 (no detections), 8.8ms\n",
            "image 47/131 /content/yolov5/Cash-Counter-11/test/images/C62860BC-2844-4544-9B6C-12F07098EB41.rf.1e4d76e680abf31538e9a86bb59628c6.jpg: 640x640 (no detections), 8.8ms\n",
            "image 48/131 /content/yolov5/Cash-Counter-11/test/images/C6E98944-1DD7-480C-B749-49E389D96646.rf.adcb7b29f84d30e5730aab1472c8720b.jpg: 640x640 (no detections), 8.8ms\n",
            "image 49/131 /content/yolov5/Cash-Counter-11/test/images/CAFE98D8-7E49-4958-8EB9-F0A2571B4365.rf.cee9434b6bc8c163126b5a3a2f501bcf.jpg: 640x640 (no detections), 8.7ms\n",
            "image 50/131 /content/yolov5/Cash-Counter-11/test/images/CE5FC0CA-E8B4-48D5-811D-1EB47EA026E9.rf.d834318a16bc1cbb456864db9ed2d239.jpg: 640x640 (no detections), 8.8ms\n",
            "image 51/131 /content/yolov5/Cash-Counter-11/test/images/D543D353-374F-4903-B27D-BDCB52B7C028.rf.411ada6f3aedfccd8f0f87905224f656.jpg: 640x640 (no detections), 8.8ms\n",
            "image 52/131 /content/yolov5/Cash-Counter-11/test/images/D700F7EA-82D4-4C36-81B6-396923AD3470.rf.4697d702f2af55fdd6ff12bd1f51f6f3.jpg: 640x640 (no detections), 8.8ms\n",
            "image 53/131 /content/yolov5/Cash-Counter-11/test/images/D70FE378-95B6-4640-8A3E-EB36FE028FCE.rf.45020f364a47362622cf3a20baf088fe.jpg: 640x640 (no detections), 8.8ms\n",
            "image 54/131 /content/yolov5/Cash-Counter-11/test/images/D959B8EF-0A47-4F17-B4F3-8E898E3081E4.rf.516fa2c7247ef433ba56377d5179deaa.jpg: 640x640 (no detections), 8.8ms\n",
            "image 55/131 /content/yolov5/Cash-Counter-11/test/images/DC3AD232-A32F-4623-A32C-3C345CA78885.rf.47cec34985ddc162fbee00e03c0ab92c.jpg: 640x640 (no detections), 8.8ms\n",
            "image 56/131 /content/yolov5/Cash-Counter-11/test/images/EC9A6263-73E1-4D04-A1C0-4D19A1CAAEDC.rf.a63517ff27c10d9442b3dd42b2bf4362.jpg: 640x640 (no detections), 8.8ms\n",
            "image 57/131 /content/yolov5/Cash-Counter-11/test/images/F6665D91-A97F-40C7-939E-0724F56CB61D.rf.1190bd1e3cf3dde47f93d340beceb843.jpg: 640x640 (no detections), 8.7ms\n",
            "image 58/131 /content/yolov5/Cash-Counter-11/test/images/F82A4609-350B-4E73-B2B1-F3A7897A137D.rf.28123a6f5aedef16ea957a4b365709e5.jpg: 640x640 (no detections), 8.8ms\n",
            "image 59/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1901_jpg.rf.ba951e0d0604529329e67a885cbb9fc9.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 60/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1905_jpg.rf.2be4f1a51018ceff3a15bd075c530671.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 61/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1908_jpg.rf.203e27d272302fe19931edc5c29b4e77.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 62/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1920_jpg.rf.3f47c19c7361ffaa4d01a6f365877b89.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 63/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1931_jpg.rf.6080e808aeec33f6ac7081a766780bf0.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 64/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1936_jpg.rf.8bb439b5ef4b5304ea14627c65d53c8e.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 65/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1941_jpg.rf.01d84aafc0209fc035c891a3f35dab20.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 66/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1951_jpg.rf.226e6ddfd29d9ec236bd723420cf17bb.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 67/131 /content/yolov5/Cash-Counter-11/test/images/IMG_1964_jpg.rf.9a8b1b4bf231fa881b542fb97cda9177.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 68/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2009_jpg.rf.b45f163c2bc35bc9f450bf26479d841f.jpg: 640x640 1 five, 8.3ms\n",
            "image 69/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2011_jpg.rf.ab8d29a86bca04f3b7178ae523652575.jpg: 640x640 1 five, 8.3ms\n",
            "image 70/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2019_jpg.rf.63707ea418856af64416dbd05c2e2b2d.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 71/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2020_jpg.rf.77cea6500bb3b1a92897000fbd241c82.jpg: 640x640 1 five, 8.3ms\n",
            "image 72/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2028_jpg.rf.d2dbd5f3a665d5c1d9559e9a3e204fa0.jpg: 640x640 1 five, 1 twenty, 8.3ms\n",
            "image 73/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2029_jpg.rf.28f171d1035d42e14a88b1a1cc7d09f1.jpg: 640x640 1 fifty, 1 five, 8.3ms\n",
            "image 74/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2047_jpg.rf.d4c3d25bc00cb3b4f38f24f45e5c2e60.jpg: 640x640 1 one, 8.4ms\n",
            "image 75/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2081_jpg.rf.bf3a82a3f17e2a2955b58f6f26ccce32.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 76/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2087_jpg.rf.1df0dbc5a8fb3644643725177ea111fb.jpg: 640x640 1 five, 10.4ms\n",
            "image 77/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2094_jpg.rf.3e70f255e403911a57c01204cdce4967.jpg: 640x640 2 ones, 8.3ms\n",
            "image 78/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2098_jpg.rf.d22a669811757e71d10c361793f0d97d.jpg: 640x640 1 ten, 8.3ms\n",
            "image 79/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-10_jpg.rf.2d34d221c55c8c2a066b3e44e441676d.jpg: 640x640 3 hundreds, 8.3ms\n",
            "image 80/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-13_jpg.rf.b16a8be1ad32bad45a87621ce897ed36.jpg: 640x640 3 hundreds, 8.3ms\n",
            "image 81/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-14_jpg.rf.f92e890d37aa3cb2a4ff262692149a39.jpg: 640x640 3 hundreds, 8.3ms\n",
            "image 82/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-17_jpg.rf.bc51ffd737fa8c48385b8e0e83a0eb51.jpg: 640x640 3 hundreds, 8.3ms\n",
            "image 83/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2152_mp4-6_jpg.rf.41b733e7d5e3c3cadb9b1e109c971f25.jpg: 640x640 3 hundreds, 8.3ms\n",
            "image 84/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2154_mp4-3_jpg.rf.2c60a73a22a82a5d19f7e2dd022a6e4f.jpg: 640x640 1 hundred, 8.3ms\n",
            "image 85/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2154_mp4-6_jpg.rf.0de4783483a6c36c5892701bb7b0ca31.jpg: 640x640 1 hundred, 8.3ms\n",
            "image 86/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2156_mp4-1_jpg.rf.bb614941b325fdff64a7a8ef2624d26e.jpg: 640x640 1 fifty, 1 twenty, 8.3ms\n",
            "image 87/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2156_mp4-8_jpg.rf.1d7e867267a830632a8644349c094173.jpg: 640x640 (no detections), 8.3ms\n",
            "image 88/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2161_jpeg_jpg.rf.ef28cd99b87eabbcbef5451b2dae20b9.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 89/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2177_jpeg_jpg.rf.fb372ef036dcf5160f66f2a9545693af.jpg: 640x640 1 one, 8.3ms\n",
            "image 90/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2186_jpeg_jpg.rf.129abb76f639fa8c4aa067231649eaff.jpg: 640x640 1 one, 8.3ms\n",
            "image 91/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2191_jpeg_jpg.rf.5e6cfece1e7645bd769c297397eef710.jpg: 640x640 1 five, 8.3ms\n",
            "image 92/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2197_jpeg_jpg.rf.038b34bd4fc20e4e32dd0d6c59d4d856.jpg: 640x640 1 five, 8.3ms\n",
            "image 93/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2204_jpeg_jpg.rf.fe2f4fac6071b68795de01f3a493b403.jpg: 640x640 1 twenty, 8.3ms\n",
            "image 94/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2228_jpeg_jpg.rf.0285c78d611bbc7ae422454915504469.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 95/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2234_jpeg_jpg.rf.96715f9aadc0a001ff43f36e0bbd7f4b.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 96/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2255_jpeg_jpg.rf.5adab7027aa07ae7c344c257269e624b.jpg: 640x640 1 ten, 8.3ms\n",
            "image 97/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2266_jpeg_jpg.rf.ab04e53ed55c88b3727d5ef805e194e1.jpg: 640x640 1 ten, 8.3ms\n",
            "image 98/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2267_jpeg_jpg.rf.c4fe47363136f619f25cc61df94eebb9.jpg: 640x640 1 ten, 8.4ms\n",
            "image 99/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2284_jpeg_jpg.rf.04556136e99ea762fc80709c0eaabaec.jpg: 640x640 1 fifty, 11.6ms\n",
            "image 100/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2307_jpeg_jpg.rf.d94d73e7e451697254754d5409fceffa.jpg: 640x640 1 five, 1 one, 1 twenty, 8.3ms\n",
            "image 101/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2312_jpeg_jpg.rf.aea7bdda8e324c639bf3e10d022efc09.jpg: 640x640 1 five, 8.3ms\n",
            "image 102/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2321_jpeg_jpg.rf.fad8623e27a470a12e10e704d7aae517.jpg: 640x640 1 one, 8.3ms\n",
            "image 103/131 /content/yolov5/Cash-Counter-11/test/images/IMG_2326_jpeg_jpg.rf.ac738904a1dd703e20ff7a94380e5ebe.jpg: 640x640 1 fifty, 8.3ms\n",
            "image 104/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8469_jpg.rf.88faf80acb3c3908a5a1de7af5e3f0c1.jpg: 640x640 8 Nickels, 8 Pennys, 8.3ms\n",
            "image 105/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8470_jpg.rf.c2359b2eec1b4f2eb860b24e45797cf4.jpg: 640x640 8 Nickels, 8 Pennys, 8.3ms\n",
            "image 106/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8472_jpg.rf.64d1b3feadd09df1ffea3c84ed0861fc.jpg: 640x640 7 Nickels, 9 Pennys, 2 Quarters, 8.3ms\n",
            "image 107/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8475_jpg.rf.d722e746c3d24cf2a247ef39d6d0d8c0.jpg: 640x640 8 Nickels, 8 Pennys, 8.3ms\n",
            "image 108/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8480_jpg.rf.2e5932e577701b9fc876de30ba7492a9.jpg: 640x640 13 Nickels, 13 Pennys, 8.3ms\n",
            "image 109/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8482_jpg.rf.84e5bfd7bd3808f150ce879cda579ee3.jpg: 640x640 13 Nickels, 13 Pennys, 8.3ms\n",
            "image 110/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8483_jpg.rf.df5fff47f5ef50456fb21cc09e8abf94.jpg: 640x640 13 Nickels, 13 Pennys, 8.4ms\n",
            "image 111/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8485_jpg.rf.f0570e571fa1215577964f8f9024042c.jpg: 640x640 13 Nickels, 13 Pennys, 8.3ms\n",
            "image 112/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8495_jpg.rf.3089a212f35f8dab42ac0e6de0ff1d24.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 113/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8495_jpg.rf.f453cf3c90b09fcdd3929328b0654b4b.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 114/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8497_jpg.rf.2013b05faa98a345f7aea608f2ebd66d.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 115/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8499_jpg.rf.f136aac8678b6e934c42cf847f8ca3f4.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 116/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8505_jpg.rf.114e12ac2cf9e949399568d2111960a1.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 117/131 /content/yolov5/Cash-Counter-11/test/images/IMG_8508_jpg.rf.1f4786e7783ce2d16610bd3eacde5642.jpg: 640x640 8 Pennys, 8 Quarters, 8.3ms\n",
            "image 118/131 /content/yolov5/Cash-Counter-11/test/images/Photo-on-10-26-21-at-2-33-PM-3_jpg.rf.18e64e41737c6d5e040246ee3d30c97b.jpg: 640x640 (no detections), 8.3ms\n",
            "image 119/131 /content/yolov5/Cash-Counter-11/test/images/Photo-on-10-26-21-at-2-37-PM-2_jpg.rf.29e1155d26d061f904903dc35017a6fc.jpg: 640x640 (no detections), 8.3ms\n",
            "image 120/131 /content/yolov5/Cash-Counter-11/test/images/S10_jpg.rf.b038e6bfd2e8bee8bc6a8a460ab209b3.jpg: 640x640 15 Dimes, 6 Nickels, 8.3ms\n",
            "image 121/131 /content/yolov5/Cash-Counter-11/test/images/S11_jpg.rf.4ea257a2254eb09dd28464f1161e4603.jpg: 640x640 15 Dimes, 8 Nickels, 8.3ms\n",
            "image 122/131 /content/yolov5/Cash-Counter-11/test/images/S13_jpg.rf.10f2cc79057ecc91d470e6936e3ffedf.jpg: 640x640 15 Dimes, 21 Pennys, 8.4ms\n",
            "image 123/131 /content/yolov5/Cash-Counter-11/test/images/S15_jpg.rf.e474b32ba63a61e489de8eb256e304ae.jpg: 640x640 3 Dimes, 1 Nickel, 21 Pennys, 8.3ms\n",
            "image 124/131 /content/yolov5/Cash-Counter-11/test/images/S1_jpg.rf.1a1b2128ae0f19ccfbe5d35649baf7d3.jpg: 640x640 15 Nickels, 9.4ms\n",
            "image 125/131 /content/yolov5/Cash-Counter-11/test/images/S21_jpg.rf.adc22c7b16e9945902a4247d7c224d42.jpg: 640x640 19 Dimes, 4 Nickels, 15 Pennys, 9.4ms\n",
            "image 126/131 /content/yolov5/Cash-Counter-11/test/images/S23_jpg.rf.199810dc4acf47b8aec37faabaf435c2.jpg: 640x640 20 Dimes, 15 Nickels, 15 Pennys, 9.5ms\n",
            "image 127/131 /content/yolov5/Cash-Counter-11/test/images/S23_jpg.rf.fcf4dd0ad67a2d991967bb4660a32ee0.jpg: 640x640 18 Dimes, 15 Nickels, 15 Pennys, 9.5ms\n",
            "image 128/131 /content/yolov5/Cash-Counter-11/test/images/S6_jpg.rf.27f7c270e5acfbdf2ea3781fd637ece1.jpg: 640x640 15 Dimes, 5 Nickels, 9.5ms\n",
            "image 129/131 /content/yolov5/Cash-Counter-11/test/images/S7_jpg.rf.d9c51f2dcaa30d794f68354d321b3de0.jpg: 640x640 16 Dimes, 1 Nickel, 9.6ms\n",
            "image 130/131 /content/yolov5/Cash-Counter-11/test/images/S9_jpg.rf.bd96f1160475fd928d87d679c99b9ea9.jpg: 640x640 17 Dimes, 3 Nickels, 9.6ms\n",
            "image 131/131 /content/yolov5/Cash-Counter-11/test/images/conveyerBoxes-AdobeStock_193267768_mov-10_jpg.rf.f65b8f806082924cbacd0fa8d78c888c.jpg: 640x640 (no detections), 9.6ms\n",
            "Speed: 0.5ms pre-process, 9.1ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp10\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Validate\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7d52f0-281c-4c96-a488-79f5908f8426"
      },
      "source": [
        "# Download COCO val\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:12<00:00, 66.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e234e05-ee8b-4ad1-b1a4-f6a55d5e4f3d"
      },
      "source": [
        "# Validate YOLOv5s on COCO val\n",
        "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ðŸš€ v7.0-136-g71244ae Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:02<00:00, 2024.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/val2017.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 157/157 [01:25<00:00,  1.84it/s]\n",
            "                   all       5000      36335      0.671      0.519      0.566      0.371\n",
            "Speed: 0.1ms pre-process, 3.1ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640)\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/val/exp/yolov5s_predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.43s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=5.32s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=78.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=14.51s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://bit.ly/ultralytics_hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/im/integrations-loop.png\"/></a></p>\n",
        "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
        "<br><br>\n",
        "\n",
        "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
        "\n",
        "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
        "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
        "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
        "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
        "<br>\n",
        "\n",
        "A **Mosaic Dataloader** is used for training which combines 4 images into 1 mosaic.\n",
        "\n",
        "## Label a dataset on Roboflow (optional)\n",
        "\n",
        "[Roboflow](https://roboflow.com/?ref=ultralytics) enables you to easily **organize, label, and prepare** a high quality dataset with your own custom data. Roboflow also makes it easy to establish an active learning pipeline, collaborate with your team on dataset improvement, and integrate directly into your model building workflow with the `roboflow` pip package."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 ðŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "id": "i3oKtE4g-aNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dbca08-be70-414b-f0aa-d8451b1d434f"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 60 --epochs 60 --data /content/yolov5/Cash-Counter-11/data.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/Cash-Counter-11/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=60, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Cash-Counter-11/train/labels.cache... 2673 images, 916 backgrounds, 0 corrupt: 100% 2673/2673 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.1GB ram): 100% 2673/2673 [00:17<00:00, 154.50it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Cash-Counter-11/valid/labels.cache... 249 images, 83 backgrounds, 0 corrupt: 100% 249/249 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 249/249 [00:04<00:00, 54.16it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.64 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/59      12.4G    0.08432    0.05731     0.0564        273        640: 100% 45/45 [00:50<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.89s/it]\n",
            "                   all        249       1379      0.588      0.207     0.0886     0.0229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/59      15.4G    0.06033    0.04166    0.04519        202        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.57s/it]\n",
            "                   all        249       1379     0.0914      0.414      0.195     0.0744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/59      15.4G    0.05277    0.03632    0.04229        306        640: 100% 45/45 [00:43<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.28s/it]\n",
            "                   all        249       1379      0.144      0.653      0.244      0.088\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/59      15.4G    0.04192     0.0347     0.0348        132        640: 100% 45/45 [00:46<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.19s/it]\n",
            "                   all        249       1379      0.274      0.745      0.383      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/59      15.4G    0.03594    0.03265     0.0288        272        640: 100% 45/45 [00:46<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all        249       1379      0.331      0.688      0.456       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/59      15.4G      0.033    0.03218    0.02366        256        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.74s/it]\n",
            "                   all        249       1379      0.397      0.688      0.493      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/59      15.4G    0.03139    0.03254    0.02385        342        640: 100% 45/45 [00:47<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.23s/it]\n",
            "                   all        249       1379      0.384      0.637       0.48      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/59      15.4G    0.03036    0.03343    0.02139        248        640: 100% 45/45 [00:46<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.16s/it]\n",
            "                   all        249       1379      0.433      0.766       0.52      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/59      15.4G    0.02881    0.03145    0.02057        207        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.49s/it]\n",
            "                   all        249       1379       0.39      0.649      0.497      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/59      15.4G    0.02835    0.03109    0.01945        195        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.10s/it]\n",
            "                   all        249       1379      0.452      0.786      0.579      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/59      15.4G    0.02824    0.03088    0.01687        288        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.16s/it]\n",
            "                   all        249       1379      0.519      0.716      0.602      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/59      15.4G    0.02715    0.03029    0.01641        347        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all        249       1379      0.488      0.816      0.636      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/59      15.4G    0.02659    0.02905     0.0151        304        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.61s/it]\n",
            "                   all        249       1379      0.464      0.867      0.656       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/59      15.4G    0.02659     0.0294    0.01441        270        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all        249       1379      0.488      0.806      0.619      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/59      15.4G    0.02583    0.02955    0.01468        348        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.07s/it]\n",
            "                   all        249       1379      0.557      0.629      0.666      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/59      15.4G    0.02518    0.02935    0.01421        260        640: 100% 45/45 [00:48<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.01it/s]\n",
            "                   all        249       1379      0.519      0.801       0.66      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/59      15.4G     0.0246    0.02821    0.01311        299        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.71s/it]\n",
            "                   all        249       1379      0.541      0.752       0.68      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/59      15.4G    0.02496     0.0291    0.01194        296        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.13s/it]\n",
            "                   all        249       1379      0.619      0.812      0.723      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/59      15.4G    0.02453    0.02906    0.01068        303        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.22s/it]\n",
            "                   all        249       1379      0.614       0.73      0.726        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/59      15.4G    0.02368    0.02753    0.01169        226        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.13s/it]\n",
            "                   all        249       1379      0.594      0.704      0.712      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/59      15.4G    0.02384    0.02757    0.01104        289        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.30s/it]\n",
            "                   all        249       1379      0.629       0.75      0.735      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/59      15.4G     0.0235    0.02837    0.01012        246        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.13s/it]\n",
            "                   all        249       1379      0.682      0.817      0.758      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/59      15.4G      0.023    0.02847   0.009311        247        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.11s/it]\n",
            "                   all        249       1379      0.676      0.761      0.768      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/59      15.4G    0.02229    0.02753    0.01096        409        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.24s/it]\n",
            "                   all        249       1379      0.622      0.801      0.756      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/59      15.4G    0.02234    0.02612   0.009579        194        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.18s/it]\n",
            "                   all        249       1379      0.703      0.818      0.758      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/59      15.4G    0.02283    0.02794   0.009453        273        640: 100% 45/45 [00:46<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.28s/it]\n",
            "                   all        249       1379       0.71      0.781      0.814      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/59      15.4G    0.02238    0.02633   0.009821        264        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.18s/it]\n",
            "                   all        249       1379      0.716      0.811      0.807      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/59      15.4G    0.02155    0.02645   0.009086        224        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.29s/it]\n",
            "                   all        249       1379      0.751      0.811        0.8        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/59      15.4G    0.02153    0.02634   0.008367        326        640: 100% 45/45 [00:43<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.19s/it]\n",
            "                   all        249       1379       0.77      0.794      0.854      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/59      15.4G    0.02114    0.02708   0.008116        208        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.00it/s]\n",
            "                   all        249       1379        0.8      0.853       0.87      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/59      15.4G      0.021    0.02534   0.007796        313        640: 100% 45/45 [00:45<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.43s/it]\n",
            "                   all        249       1379       0.79      0.866       0.88      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/59      15.4G    0.02097    0.02554   0.007399        130        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.47s/it]\n",
            "                   all        249       1379      0.806      0.816      0.856      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/59      15.4G    0.02067    0.02593   0.007156        293        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.05s/it]\n",
            "                   all        249       1379      0.838      0.835      0.904      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/59      15.4G    0.02063    0.02594   0.006907        306        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all        249       1379      0.807      0.898      0.895      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/59      15.4G     0.0204    0.02468   0.006947        278        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.08s/it]\n",
            "                   all        249       1379      0.838      0.819      0.882      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/59      15.4G     0.0204    0.02555   0.006321        161        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all        249       1379      0.828      0.842      0.899      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/59      15.4G    0.02031    0.02642    0.00601        285        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.12s/it]\n",
            "                   all        249       1379      0.821       0.85      0.896       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/59      15.4G    0.01976    0.02611   0.005809        342        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.29s/it]\n",
            "                   all        249       1379      0.875      0.867      0.939      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/59      15.4G    0.01978    0.02524   0.005758        250        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.19s/it]\n",
            "                   all        249       1379      0.884      0.863      0.925      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/59      15.4G    0.01942     0.0247   0.005735        187        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.10s/it]\n",
            "                   all        249       1379      0.894      0.832      0.919      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/59      15.4G    0.01928     0.0257   0.005829        240        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.57s/it]\n",
            "                   all        249       1379      0.879      0.825      0.915      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/59      15.4G    0.01892    0.02505   0.005231        249        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.08it/s]\n",
            "                   all        249       1379      0.896      0.859      0.932      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/59      15.4G     0.0191    0.02488   0.005123        287        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.65s/it]\n",
            "                   all        249       1379      0.936      0.895      0.969      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/59      15.4G     0.0189     0.0243   0.004762        218        640: 100% 45/45 [00:44<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.11s/it]\n",
            "                   all        249       1379      0.933      0.907      0.966      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/59      15.4G    0.01884    0.02488   0.004675        232        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   all        249       1379      0.935      0.882      0.967      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/59      15.4G    0.01874    0.02434   0.004771        210        640: 100% 45/45 [00:45<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.60s/it]\n",
            "                   all        249       1379      0.943      0.897      0.974       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/59      15.4G    0.01811    0.02443   0.004478        298        640: 100% 45/45 [00:43<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.21s/it]\n",
            "                   all        249       1379      0.974      0.881      0.975      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/59      15.4G    0.01812    0.02513   0.003859        388        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.40s/it]\n",
            "                   all        249       1379      0.924      0.902      0.967      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/59      15.4G    0.01818    0.02456   0.003951        306        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.08s/it]\n",
            "                   all        249       1379      0.954      0.883      0.967       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/59      15.4G    0.01799     0.0247    0.00407        273        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all        249       1379      0.941      0.909       0.97      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/59      15.4G     0.0177     0.0233   0.003917        359        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.48s/it]\n",
            "                   all        249       1379      0.956      0.924      0.981      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/59      15.4G    0.01744    0.02384   0.003675        237        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.09s/it]\n",
            "                   all        249       1379      0.926      0.895      0.965      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/59      15.4G    0.01731    0.02383   0.003307        293        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.41s/it]\n",
            "                   all        249       1379      0.922      0.902      0.975      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/59      15.4G    0.01752    0.02357   0.003412        223        640: 100% 45/45 [00:45<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.25s/it]\n",
            "                   all        249       1379      0.976      0.911      0.979      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/59      15.4G     0.0168    0.02394   0.003242        362        640: 100% 45/45 [00:47<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.09s/it]\n",
            "                   all        249       1379      0.953      0.909      0.976        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/59      15.4G    0.01682    0.02234   0.003242        351        640: 100% 45/45 [00:44<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.57s/it]\n",
            "                   all        249       1379      0.966      0.927      0.979      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/59      15.4G    0.01726    0.02352   0.003401        232        640: 100% 45/45 [00:45<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.16s/it]\n",
            "                   all        249       1379      0.967      0.918      0.977      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/59      15.4G     0.0169     0.0237    0.00297        391        640: 100% 45/45 [00:46<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.08s/it]\n",
            "                   all        249       1379       0.96      0.913      0.978      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/59      15.4G    0.01692    0.02331   0.003214        330        640: 100% 45/45 [00:44<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.47s/it]\n",
            "                   all        249       1379      0.944      0.936      0.979       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/59      15.4G    0.01651    0.02326   0.002934        330        640: 100% 45/45 [00:47<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.15s/it]\n",
            "                   all        249       1379       0.96      0.912      0.977      0.815\n",
            "\n",
            "60 epochs completed in 0.846 hours.\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp3/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all        249       1379       0.96      0.912      0.977      0.815\n",
            "                  Dime        249        202      0.961      0.974      0.975      0.716\n",
            "                Nickel        249        357      0.974      0.933      0.982      0.793\n",
            "                 Penny        249        502      0.996      0.994      0.994      0.812\n",
            "               Quarter        249        214      0.912      0.963      0.989      0.834\n",
            "                 fifty        249         15      0.849          1      0.995      0.877\n",
            "                  five        249         15          1      0.925      0.985       0.88\n",
            "               hundred        249         20          1      0.547      0.914      0.641\n",
            "                   one        249         20      0.974          1      0.995      0.875\n",
            "                   ten        249         16      0.996          1      0.995       0.89\n",
            "                twenty        249         18      0.934      0.787       0.95      0.834\n",
            "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comet Logging and Visualization ðŸŒŸ NEW\n",
        "\n",
        "[Comet](https://www.comet.com/site/lp/yolov5-with-comet/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab) is now fully integrated with YOLOv5. Track and visualize model metrics in real time, save your hyperparameters, datasets, and model checkpoints, and visualize your model predictions with [Comet Custom Panels](https://www.comet.com/docs/v2/guides/comet-dashboard/code-panels/about-panels/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab)! Comet makes sure you never lose track of your work and makes it easy to share results and collaborate across teams of all sizes!\n",
        "\n",
        "Getting started is easy:\n",
        "```shell\n",
        "pip install comet_ml  # 1. install\n",
        "export COMET_API_KEY=<Your API Key>  # 2. paste API key\n",
        "python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train\n",
        "```\n",
        "To learn more about all of the supported Comet features for this integration, check out the [Comet Tutorial](https://docs.ultralytics.com/yolov5/tutorials/comet_logging_integration). If you'd like to learn more about Comet, head over to our [documentation](https://www.comet.com/docs/v2/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab). Get started by trying out the Comet Colab Notebook:\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing)\n",
        "\n",
        "<a href=\"https://bit.ly/yolov5-readme-comet2\">\n",
        "<img alt=\"Comet Dashboard\" src=\"https://user-images.githubusercontent.com/26833433/202851203-164e94e1-2238-46dd-91f8-de020e9d6b41.png\" width=\"1280\"/></a>"
      ],
      "metadata": {
        "id": "nWOsI5wJR1o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ClearML Logging and Automation ðŸŒŸ NEW\n",
        "\n",
        "[ClearML](https://cutt.ly/yolov5-notebook-clearml) is completely integrated into YOLOv5 to track your experimentation, manage dataset versions and even remotely execute training runs. To enable ClearML (check cells above):\n",
        "\n",
        "- `pip install clearml`\n",
        "- run `clearml-init` to connect to a ClearML server (**deploy your own [open-source server](https://github.com/allegroai/clearml-server)**, or use our [free hosted server](https://cutt.ly/yolov5-notebook-clearml))\n",
        "\n",
        "You'll get all the great expected features from an experiment manager: live updates, model upload, experiment comparison etc. but ClearML also tracks uncommitted changes and installed packages for example. Thanks to that ClearML Tasks (which is what we call experiments) are also reproducible on different machines! With only 1 extra line, we can schedule a YOLOv5 training task on a queue to be executed by any number of ClearML Agents (workers).\n",
        "\n",
        "You can use ClearML Data to version your dataset and then pass it to YOLOv5 simply using its unique ID. This will help you keep track of your data without adding extra hassle. Explore the [ClearML Tutorial](https://docs.ultralytics.com/yolov5/tutorials/clearml_logging_integration) for details!\n",
        "\n",
        "<a href=\"https://cutt.ly/yolov5-notebook-clearml\">\n",
        "<img alt=\"ClearML Experiment Management UI\" src=\"https://github.com/thepycoder/clearml_screenshots/raw/main/scalars.jpg\" width=\"1280\"/></a>"
      ],
      "metadata": {
        "id": "Lay2WsTjNJzP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPvRbS5Swl6"
      },
      "source": [
        "## Local Logging\n",
        "\n",
        "Training results are automatically logged with [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) loggers to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc.\n",
        "\n",
        "This directory contains train and val statistics, mosaics, labels, predictions and augmentated mosaics, as well as metrics and charts including precision-recall (PR) curves and confusion matrices. \n",
        "\n",
        "<img alt=\"Local logging results\" src=\"https://user-images.githubusercontent.com/26833433/183222430-e1abd1b7-782c-4cde-b04d-ad52926bf818.jpg\" width=\"1280\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "# Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Notebooks** with free GPU: <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a> <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "# Status\n",
        "\n",
        "![YOLOv5 CI](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on macOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}