{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1:  install(clone) the yolov5  model ♒**\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1a_wJ9hnURCd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef5f583-ee5c-43c7-b079-c094f397a210"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ♒ **Step 2:  download the  dataset  ( from roboflow)**"
      ],
      "metadata": {
        "id": "Y3kOQ4rpU4Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"fsONItcf1hfpiPVIYf74\")\n",
        "project = rf.workspace(\"projects-gvrv7\").project(\"crowd-counting-uiyz6\")\n",
        "dataset = project.version(2).download(\"yolov5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbs3f_1uyzH_",
        "outputId": "c84e29b3-78c0-475e-b337-5825f9bbb951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (8.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.15)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=61c9dcae7b1ee82c8c2d3b1d25f36dffec271275874e5a9c75701d9746a91d71\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.0.9 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in crowd-counting-2 to yolov5pytorch: 100% [13378337 / 13378337] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to crowd-counting-2 in yolov5pytorch:: 100%|██████████| 412/412 [00:00<00:00, 1710.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: train the model  ♒**"
      ],
      "metadata": {
        "id": "ok1uwvBxVzV-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb1c534-fc82-4431-9fac-1b0bccdee6f5"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 60 --epochs 60 --data /content/yolov5/crowd-counting-2/data.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/crowd-counting-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=60, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 50.2MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/crowd-counting-2/train/labels... 140 images, 0 backgrounds, 0 corrupt: 100% 140/140 [00:00<00:00, 1453.80it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/crowd-counting-2/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 140/140 [00:00<00:00, 174.45it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/crowd-counting-2/valid/labels... 40 images, 0 backgrounds, 0 corrupt: 100% 40/40 [00:00<00:00, 608.26it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/crowd-counting-2/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 40/40 [00:01<00:00, 39.54it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/59      12.4G     0.1235    0.09452          0        416        640: 100% 3/3 [00:09<00:00,  3.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.500s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.49s/it]\n",
            "                   all         40        593     0.0014     0.0135   0.000719   8.95e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/59      12.4G       0.12     0.1035          0        491        640: 100% 3/3 [00:01<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.500s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "                   all         40        593      0.005     0.0658    0.00389    0.00101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/59      12.4G     0.1144     0.1111          0        523        640: 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "                   all         40        593     0.0322     0.0759     0.0243     0.0056\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/59      12.4G     0.1072     0.1253          0        472        640: 100% 3/3 [00:01<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "                   all         40        593       0.13     0.0927      0.065     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/59      12.4G     0.1001     0.1229          0        360        640: 100% 3/3 [00:01<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.22s/it]\n",
            "                   all         40        593        0.2      0.251       0.16     0.0448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/59      12.4G    0.09583     0.1197          0        436        640: 100% 3/3 [00:01<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                   all         40        593      0.351       0.41      0.311     0.0908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/59      12.4G    0.09334     0.1269          0        669        640: 100% 3/3 [00:01<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
            "                   all         40        593      0.335      0.479      0.315     0.0865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/59      12.4G    0.08558     0.1188          0        509        640: 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.10s/it]\n",
            "                   all         40        593      0.327      0.501      0.344      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/59      12.4G    0.07962     0.1124          0        461        640: 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.41s/it]\n",
            "                   all         40        593      0.325      0.504      0.344      0.109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/59      12.4G     0.0785     0.1084          0        426        640: 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.28s/it]\n",
            "                   all         40        593       0.34      0.484      0.364      0.127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/59      12.4G    0.07544     0.1138          0        488        640: 100% 3/3 [00:01<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.26s/it]\n",
            "                   all         40        593      0.346      0.455      0.393      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/59      12.4G    0.07778     0.1157          0        552        640: 100% 3/3 [00:01<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
            "                   all         40        593      0.377      0.513      0.439      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/59      12.4G    0.07354     0.1214          0        581        640: 100% 3/3 [00:01<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.06it/s]\n",
            "                   all         40        593      0.352      0.521      0.407      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/59      12.4G    0.06878     0.1087          0        403        640: 100% 3/3 [00:01<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.14s/it]\n",
            "                   all         40        593      0.391       0.56      0.488      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/59      12.4G    0.06873     0.1116          0        527        640: 100% 3/3 [00:01<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.04s/it]\n",
            "                   all         40        593       0.44      0.612      0.544      0.254\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/59      12.4G    0.06626     0.1115          0        551        640: 100% 3/3 [00:01<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         40        593      0.345      0.621       0.38      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/59      12.4G    0.06573     0.1109          0        393        640: 100% 3/3 [00:02<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "                   all         40        593       0.63      0.676      0.644      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/59      12.4G     0.0686    0.09692          0        346        640: 100% 3/3 [00:01<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
            "                   all         40        593      0.498       0.62      0.567      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/59      12.4G     0.0662     0.1117          0        507        640: 100% 3/3 [00:02<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                   all         40        593       0.58      0.626      0.637      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/59      12.4G    0.06463     0.1093          0        450        640: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.06it/s]\n",
            "                   all         40        593      0.486      0.602      0.552      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/59      12.4G    0.06378     0.1026          0        458        640: 100% 3/3 [00:02<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         40        593      0.583      0.628      0.642      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/59      12.4G    0.06197     0.1106          0        568        640: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.09it/s]\n",
            "                   all         40        593       0.56      0.666      0.635      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/59      12.4G    0.06407      0.106          0        452        640: 100% 3/3 [00:02<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "                   all         40        593      0.731      0.691      0.737      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/59      12.4G    0.06224     0.1008          0        459        640: 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         40        593      0.567      0.636      0.638      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/59      12.4G    0.06151       0.11          0        567        640: 100% 3/3 [00:01<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "                   all         40        593       0.51      0.685      0.615        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/59      12.4G    0.06128     0.1064          0        568        640: 100% 3/3 [00:01<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         40        593      0.705      0.691      0.711      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/59      12.4G       0.06     0.1041          0        390        640: 100% 3/3 [00:01<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         40        593       0.64      0.649      0.678      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/59      12.4G    0.05955      0.102          0        358        640: 100% 3/3 [00:01<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         40        593      0.629      0.631      0.682      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/59      12.4G    0.05944     0.1092          0        494        640: 100% 3/3 [00:02<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                   all         40        593      0.662      0.712      0.724      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/59      12.4G    0.05926     0.1004          0        394        640: 100% 3/3 [00:02<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         40        593      0.681      0.712      0.738      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/59      12.4G    0.06003     0.1001          0        524        640: 100% 3/3 [00:01<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         40        593      0.792      0.703      0.806      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/59      12.4G     0.0581    0.09827          0        491        640: 100% 3/3 [00:02<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "                   all         40        593      0.684      0.665       0.72      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/59      12.4G    0.05621     0.1019          0        482        640: 100% 3/3 [00:02<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         40        593      0.761      0.722      0.802      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/59      12.4G    0.05576     0.1035          0        513        640: 100% 3/3 [00:02<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         40        593      0.698      0.712      0.738      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/59      12.4G    0.05723     0.1097          0        546        640: 100% 3/3 [00:01<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.31s/it]\n",
            "                   all         40        593      0.756      0.725      0.798      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/59      12.4G    0.05529    0.09879          0        399        640: 100% 3/3 [00:02<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.22it/s]\n",
            "                   all         40        593       0.83      0.693      0.804      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/59      12.4G    0.05321    0.09572          0        452        640: 100% 3/3 [00:01<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         40        593      0.841      0.696       0.81      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/59      12.4G    0.05153    0.09987          0        384        640: 100% 3/3 [00:01<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "                   all         40        593      0.836      0.713      0.826      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/59      12.4G    0.05262     0.1014          0        496        640: 100% 3/3 [00:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                   all         40        593       0.76      0.738      0.781      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/59      12.4G    0.05212     0.1019          0        521        640: 100% 3/3 [00:02<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         40        593      0.726      0.737      0.782      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/59      12.4G    0.05433     0.1096          0        614        640: 100% 3/3 [00:01<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "                   all         40        593       0.83       0.72      0.828      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/59      12.4G    0.05024     0.1034          0        465        640: 100% 3/3 [00:01<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all         40        593      0.836      0.739      0.835      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/59      12.4G    0.04954      0.105          0        503        640: 100% 3/3 [00:02<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.08it/s]\n",
            "                   all         40        593       0.85      0.725      0.829      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/59      12.4G    0.04813    0.09583          0        455        640: 100% 3/3 [00:01<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.58it/s]\n",
            "                   all         40        593      0.858      0.727      0.831      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/59      12.4G    0.04658    0.09186          0        391        640: 100% 3/3 [00:02<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         40        593      0.817      0.732      0.817      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/59      12.4G     0.0474    0.09822          0        455        640: 100% 3/3 [00:02<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.22it/s]\n",
            "                   all         40        593      0.842      0.713      0.822      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/59      12.4G    0.04675    0.09957          0        431        640: 100% 3/3 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.08it/s]\n",
            "                   all         40        593      0.843      0.722      0.829      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/59      12.4G    0.04712     0.1097          0        545        640: 100% 3/3 [00:01<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         40        593      0.853      0.747      0.839      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/59      12.4G    0.04783     0.1115          0        538        640: 100% 3/3 [00:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.17s/it]\n",
            "                   all         40        593      0.841      0.745      0.843      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/59      12.4G     0.0471    0.09963          0        502        640: 100% 3/3 [00:02<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.10it/s]\n",
            "                   all         40        593      0.809      0.764      0.837      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/59      12.4G    0.04585    0.09233          0        473        640: 100% 3/3 [00:02<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         40        593      0.786      0.791      0.846      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/59      12.4G    0.04519     0.1026          0        540        640: 100% 3/3 [00:01<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         40        593      0.796      0.784       0.84      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/59      12.4G    0.04519    0.09539          0        499        640: 100% 3/3 [00:02<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         40        593      0.843      0.731      0.835      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/59      12.4G     0.0436    0.09557          0        454        640: 100% 3/3 [00:01<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.22it/s]\n",
            "                   all         40        593       0.85      0.746      0.845      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/59      12.4G    0.04449    0.09619          0        525        640: 100% 3/3 [00:01<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.16s/it]\n",
            "                   all         40        593      0.826      0.762      0.847      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/59      12.4G    0.04492    0.09604          0        470        640: 100% 3/3 [00:02<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                   all         40        593      0.827      0.744      0.838      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/59      12.4G    0.04359     0.0993          0        508        640: 100% 3/3 [00:01<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "                   all         40        593      0.842      0.745      0.845      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/59      12.4G     0.0441     0.0951          0        397        640: 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         40        593      0.815      0.759      0.843      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/59      12.4G    0.04562     0.1106          0        629        640: 100% 3/3 [00:01<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "                   all         40        593       0.81      0.772       0.84      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/59      12.4G    0.04533    0.09814          0        575        640: 100% 3/3 [00:01<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         40        593      0.821      0.767      0.844      0.513\n",
            "\n",
            "60 epochs completed in 0.073 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         40        593      0.821      0.766      0.843      0.513\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step4: detect the object from images through the trained model:**:"
      ],
      "metadata": {
        "id": "41AtwFwPbBhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.25 --source /content/yolov5/crowd-counting-2/test/images"
      ],
      "metadata": {
        "id": "Jojj1ieIbH7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step 5: convert the trained model in .pt to .tflite  (tensorflow lite ) for mobile app ♒ **bold text**"
      ],
      "metadata": {
        "id": "mI0zvsFJVd2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights  runs/train/exp/weights/best.pt --include tflite --img 640"
      ],
      "metadata": {
        "id": "TwysBfCUdjf-",
        "outputId": "bdc8a0a8-6e61-412d-922e-7f5e1be899ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['runs/train/exp/weights/best.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/train/exp/weights/best.pt with output shape (1, 25200, 6) (13.8 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2023-06-09 18:37:34.745376: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     115200      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     656128      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     131328      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 6),      16182       ['tfc3_5[0][0]',                 \n",
            "                                )                                 'tfc3_6[0][0]',                 \n",
            "                                                                  'tfc3_7[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,012,822\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,012,822\n",
            "__________________________________________________________________________________________________\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 9.8s, saved as runs/train/exp/weights/best_saved_model (27.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "WARNING:absl:Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 268). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 63.6s, saved as runs/train/exp/weights/best-fp16.tflite (13.5 MB)\n",
            "\n",
            "Export complete (74.9s)\n",
            "Results saved to \u001b[1m/content/yolov5/runs/train/exp/weights\u001b[0m\n",
            "Detect:          python detect.py --weights runs/train/exp/weights/best-fp16.tflite \n",
            "Validate:        python val.py --weights runs/train/exp/weights/best-fp16.tflite \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/exp/weights/best-fp16.tflite')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **step 6: detect the object from images through the converted tensorflow lite trained model::**:"
      ],
      "metadata": {
        "id": "ZYwQlZodb3ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best-fp16.tflite --img 640 --conf 0.25 --source /content/yolov5/crowd-counting-2/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5wPBWL-cWw-",
        "outputId": "02fb4c2c-5645-437e-90d9-cb9d5e18e22d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best-fp16.tflite'], source=/content/yolov5/crowd-counting-2/test/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading runs/train/exp/weights/best-fp16.tflite for TensorFlow Lite inference...\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "image 1/20 /content/yolov5/crowd-counting-2/test/images/0019_jpg.rf.a0b6607b8b280e489ae1e65a7fe3f495.jpg: 640x640 22 persons, 548.3ms\n",
            "image 2/20 /content/yolov5/crowd-counting-2/test/images/0023_jpg.rf.c84c146e403a651d0e6c9d64d5501606.jpg: 640x640 23 persons, 454.7ms\n",
            "image 3/20 /content/yolov5/crowd-counting-2/test/images/0808_jpg.rf.ec927da9c3624520582a116c9e95a980.jpg: 640x640 31 persons, 452.1ms\n",
            "image 4/20 /content/yolov5/crowd-counting-2/test/images/1342_jpg.rf.5c48f9ea29668af47ed50e8a21d173fa.jpg: 640x640 37 persons, 463.7ms\n",
            "image 5/20 /content/yolov5/crowd-counting-2/test/images/273271-1a27b000f0c7a077_jpg.rf.5d1ac53eb7c8da68c038aa6d5be1d7cd.jpg: 640x640 17 persons, 450.7ms\n",
            "image 6/20 /content/yolov5/crowd-counting-2/test/images/273271-1c3690007edf2e3c_jpg.rf.cf8b98e2f6c081030f4e63ce8625e897.jpg: 640x640 8 persons, 445.7ms\n",
            "image 7/20 /content/yolov5/crowd-counting-2/test/images/273271-1c50900088104e31_jpg.rf.ae6df494ed2a1e5b4d3e7f71718dbc6d.jpg: 640x640 7 persons, 443.1ms\n",
            "image 8/20 /content/yolov5/crowd-counting-2/test/images/273271-1c76f000a7edecb7_jpg.rf.c293b83efe7b28b5018a3828768d095b.jpg: 640x640 4 persons, 440.6ms\n",
            "image 9/20 /content/yolov5/crowd-counting-2/test/images/273271-1d9020000aa06396_jpg.rf.8d6f832742a3b837dd85695347f155f1.jpg: 640x640 5 persons, 453.6ms\n",
            "image 10/20 /content/yolov5/crowd-counting-2/test/images/273271-1e78b000033a6a0c_jpg.rf.b4c5abcac6c5be535523aa6ef31ea08f.jpg: 640x640 8 persons, 440.9ms\n",
            "image 11/20 /content/yolov5/crowd-counting-2/test/images/273271-1ec02000cc829bb5_jpg.rf.ffb7cc33124ae9f3d2fdd4c92be1b8dc.jpg: 640x640 7 persons, 438.3ms\n",
            "image 12/20 /content/yolov5/crowd-counting-2/test/images/273271-1f68100063eca86d_jpg.rf.5d5ac9325b3b1714aa978a1e6b68faf5.jpg: 640x640 7 persons, 438.9ms\n",
            "image 13/20 /content/yolov5/crowd-counting-2/test/images/273271-1fb9e0005115eb97_jpg.rf.207e1252e1965b83ada1ba3c1516e910.jpg: 640x640 5 persons, 443.3ms\n",
            "image 14/20 /content/yolov5/crowd-counting-2/test/images/273271-2a540000116dd49a_jpg.rf.d72540d648d362dd8162f0ab77cf197a.jpg: 640x640 21 persons, 444.8ms\n",
            "image 15/20 /content/yolov5/crowd-counting-2/test/images/273275-398e000001132e3a_jpg.rf.09978381c1e6274ca67665534ebe9667.jpg: 640x640 16 persons, 446.3ms\n",
            "image 16/20 /content/yolov5/crowd-counting-2/test/images/284193-eb99000edd998dc_jpg.rf.d1f1f3114ca9dff44f46ebe9ed52bc73.jpg: 640x640 8 persons, 435.4ms\n",
            "image 17/20 /content/yolov5/crowd-counting-2/test/images/seq_001310_jpg.rf.900788625e010ce1ef491cb90e0cceba.jpg: 640x640 29 persons, 444.3ms\n",
            "image 18/20 /content/yolov5/crowd-counting-2/test/images/seq_001326_jpg.rf.8155c6ccde4390c35ed70e0bf3bc365d.jpg: 640x640 26 persons, 457.7ms\n",
            "image 19/20 /content/yolov5/crowd-counting-2/test/images/seq_001330_jpg.rf.19e38d2a178771e255919ea4c098db8f.jpg: 640x640 17 persons, 448.2ms\n",
            "image 20/20 /content/yolov5/crowd-counting-2/test/images/seq_001661_jpg.rf.13c3fcbaec0fb997b6b0ef9be46df933.jpg: 640x640 28 persons, 458.8ms\n",
            "Speed: 3.1ms pre-process, 452.5ms inference, 7.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **step7: detect the objects from video**:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VWwEz1fPc9o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best-fp16.tflite --img 640 --conf 0.25 --source /content/pexels-pixabay-855565-1920x1080-24fps.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7Mul_F-ewW-",
        "outputId": "9e9bc89d-1c73-469e-8e41-07c113c3eca4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best-fp16.tflite'], source=/content/pexels-pixabay-855565-1920x1080-24fps.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading runs/train/exp/weights/best-fp16.tflite for TensorFlow Lite inference...\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "video 1/1 (1/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 520.2ms\n",
            "video 1/1 (2/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 458.0ms\n",
            "video 1/1 (3/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 472.3ms\n",
            "video 1/1 (4/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 456.7ms\n",
            "video 1/1 (5/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 666.0ms\n",
            "video 1/1 (6/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 695.9ms\n",
            "video 1/1 (7/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 705.1ms\n",
            "video 1/1 (8/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 690.7ms\n",
            "video 1/1 (9/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 748.9ms\n",
            "video 1/1 (10/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 703.2ms\n",
            "video 1/1 (11/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 663.4ms\n",
            "video 1/1 (12/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 703.6ms\n",
            "video 1/1 (13/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 603.6ms\n",
            "video 1/1 (14/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 442.4ms\n",
            "video 1/1 (15/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 464.7ms\n",
            "video 1/1 (16/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 454.8ms\n",
            "video 1/1 (17/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 458.0ms\n",
            "video 1/1 (18/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 456.6ms\n",
            "video 1/1 (19/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 457.0ms\n",
            "video 1/1 (20/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 450.5ms\n",
            "video 1/1 (21/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 465.7ms\n",
            "video 1/1 (22/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 457.1ms\n",
            "video 1/1 (23/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 466.0ms\n",
            "video 1/1 (24/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 448.4ms\n",
            "video 1/1 (25/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 13 persons, 457.7ms\n",
            "video 1/1 (26/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 445.1ms\n",
            "video 1/1 (27/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 13 persons, 445.2ms\n",
            "video 1/1 (28/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 613.4ms\n",
            "video 1/1 (29/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 674.6ms\n",
            "video 1/1 (30/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 702.0ms\n",
            "video 1/1 (31/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 683.5ms\n",
            "video 1/1 (32/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 599.9ms\n",
            "video 1/1 (33/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 466.0ms\n",
            "video 1/1 (34/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 457.7ms\n",
            "video 1/1 (35/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 464.8ms\n",
            "video 1/1 (36/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 472.3ms\n",
            "video 1/1 (37/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 452.8ms\n",
            "video 1/1 (38/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 453.4ms\n",
            "video 1/1 (39/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 472.3ms\n",
            "video 1/1 (40/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 455.1ms\n",
            "video 1/1 (41/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 448.9ms\n",
            "video 1/1 (42/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 461.6ms\n",
            "video 1/1 (43/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 461.9ms\n",
            "video 1/1 (44/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 463.7ms\n",
            "video 1/1 (45/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 438.4ms\n",
            "video 1/1 (46/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 465.9ms\n",
            "video 1/1 (47/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 454.0ms\n",
            "video 1/1 (48/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 461.0ms\n",
            "video 1/1 (49/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 446.7ms\n",
            "video 1/1 (50/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 452.4ms\n",
            "video 1/1 (51/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 459.2ms\n",
            "video 1/1 (52/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 449.6ms\n",
            "video 1/1 (53/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 663.3ms\n",
            "video 1/1 (54/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 688.3ms\n",
            "video 1/1 (55/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 665.6ms\n",
            "video 1/1 (56/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 653.8ms\n",
            "video 1/1 (57/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 599.3ms\n",
            "video 1/1 (58/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 457.8ms\n",
            "video 1/1 (59/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 473.4ms\n",
            "video 1/1 (60/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 466.0ms\n",
            "video 1/1 (61/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 463.4ms\n",
            "video 1/1 (62/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 458.5ms\n",
            "video 1/1 (63/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 450.8ms\n",
            "video 1/1 (64/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 452.1ms\n",
            "video 1/1 (65/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 476.7ms\n",
            "video 1/1 (66/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 467.6ms\n",
            "video 1/1 (67/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 457.5ms\n",
            "video 1/1 (68/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 447.3ms\n",
            "video 1/1 (69/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 440.2ms\n",
            "video 1/1 (70/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 466.7ms\n",
            "video 1/1 (71/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 439.3ms\n",
            "video 1/1 (72/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 453.2ms\n",
            "video 1/1 (73/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 451.9ms\n",
            "video 1/1 (74/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 459.4ms\n",
            "video 1/1 (75/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 447.4ms\n",
            "video 1/1 (76/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 456.6ms\n",
            "video 1/1 (77/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 444.0ms\n",
            "video 1/1 (78/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 672.9ms\n",
            "video 1/1 (79/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 707.6ms\n",
            "video 1/1 (80/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 652.5ms\n",
            "video 1/1 (81/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 693.4ms\n",
            "video 1/1 (82/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 575.9ms\n",
            "video 1/1 (83/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 447.8ms\n",
            "video 1/1 (84/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 461.0ms\n",
            "video 1/1 (85/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 447.5ms\n",
            "video 1/1 (86/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 462.2ms\n",
            "video 1/1 (87/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 473.2ms\n",
            "video 1/1 (88/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 464.2ms\n",
            "video 1/1 (89/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 455.7ms\n",
            "video 1/1 (90/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 453.4ms\n",
            "video 1/1 (91/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 457.5ms\n",
            "video 1/1 (92/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 445.1ms\n",
            "video 1/1 (93/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 470.5ms\n",
            "video 1/1 (94/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 459.9ms\n",
            "video 1/1 (95/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 452.5ms\n",
            "video 1/1 (96/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 453.9ms\n",
            "video 1/1 (97/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 14 persons, 455.4ms\n",
            "video 1/1 (98/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 450.6ms\n",
            "video 1/1 (99/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 13 persons, 461.8ms\n",
            "video 1/1 (100/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 450.4ms\n",
            "video 1/1 (101/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 465.4ms\n",
            "video 1/1 (102/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 470.8ms\n",
            "video 1/1 (103/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 11 persons, 658.6ms\n",
            "video 1/1 (104/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 683.6ms\n",
            "video 1/1 (105/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 657.7ms\n",
            "video 1/1 (106/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 667.1ms\n",
            "video 1/1 (107/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 574.9ms\n",
            "video 1/1 (108/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 453.3ms\n",
            "video 1/1 (109/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 462.7ms\n",
            "video 1/1 (110/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 453.8ms\n",
            "video 1/1 (111/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 470.4ms\n",
            "video 1/1 (112/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 440.0ms\n",
            "video 1/1 (113/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 445.9ms\n",
            "video 1/1 (114/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 471.3ms\n",
            "video 1/1 (115/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 456.8ms\n",
            "video 1/1 (116/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 461.8ms\n",
            "video 1/1 (117/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 469.4ms\n",
            "video 1/1 (118/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 449.9ms\n",
            "video 1/1 (119/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 452.6ms\n",
            "video 1/1 (120/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 459.4ms\n",
            "video 1/1 (121/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 482.4ms\n",
            "video 1/1 (122/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 471.8ms\n",
            "video 1/1 (123/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 475.9ms\n",
            "video 1/1 (124/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 457.1ms\n",
            "video 1/1 (125/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 457.0ms\n",
            "video 1/1 (126/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 450.8ms\n",
            "video 1/1 (127/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 482.2ms\n",
            "video 1/1 (128/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 671.1ms\n",
            "video 1/1 (129/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 649.9ms\n",
            "video 1/1 (130/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 697.1ms\n",
            "video 1/1 (131/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 667.6ms\n",
            "video 1/1 (132/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 3 persons, 493.2ms\n",
            "video 1/1 (133/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 459.4ms\n",
            "video 1/1 (134/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 444.6ms\n",
            "video 1/1 (135/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 459.2ms\n",
            "video 1/1 (136/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 441.8ms\n",
            "video 1/1 (137/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 468.7ms\n",
            "video 1/1 (138/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 440.1ms\n",
            "video 1/1 (139/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 460.4ms\n",
            "video 1/1 (140/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 448.9ms\n",
            "video 1/1 (141/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 458.2ms\n",
            "video 1/1 (142/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 439.8ms\n",
            "video 1/1 (143/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 458.3ms\n",
            "video 1/1 (144/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 452.5ms\n",
            "video 1/1 (145/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 465.0ms\n",
            "video 1/1 (146/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 3 persons, 444.3ms\n",
            "video 1/1 (147/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 468.0ms\n",
            "video 1/1 (148/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 3 persons, 438.3ms\n",
            "video 1/1 (149/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 443.8ms\n",
            "video 1/1 (150/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 445.7ms\n",
            "video 1/1 (151/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 449.0ms\n",
            "video 1/1 (152/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 463.1ms\n",
            "video 1/1 (153/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 661.8ms\n",
            "video 1/1 (154/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 666.6ms\n",
            "video 1/1 (155/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 698.6ms\n",
            "video 1/1 (156/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 680.9ms\n",
            "video 1/1 (157/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 551.7ms\n",
            "video 1/1 (158/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 4 persons, 459.9ms\n",
            "video 1/1 (159/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 457.6ms\n",
            "video 1/1 (160/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 458.4ms\n",
            "video 1/1 (161/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 445.5ms\n",
            "video 1/1 (162/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 466.7ms\n",
            "video 1/1 (163/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 454.8ms\n",
            "video 1/1 (164/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 5 persons, 461.8ms\n",
            "video 1/1 (165/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 444.2ms\n",
            "video 1/1 (166/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 6 persons, 467.7ms\n",
            "video 1/1 (167/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 459.3ms\n",
            "video 1/1 (168/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 7 persons, 461.8ms\n",
            "video 1/1 (169/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 451.2ms\n",
            "video 1/1 (170/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 8 persons, 465.2ms\n",
            "video 1/1 (171/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 449.8ms\n",
            "video 1/1 (172/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 477.6ms\n",
            "video 1/1 (173/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 447.0ms\n",
            "video 1/1 (174/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 464.2ms\n",
            "video 1/1 (175/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 459.6ms\n",
            "video 1/1 (176/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 466.8ms\n",
            "video 1/1 (177/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 489.9ms\n",
            "video 1/1 (178/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 706.0ms\n",
            "video 1/1 (179/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 714.6ms\n",
            "video 1/1 (180/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 729.9ms\n",
            "video 1/1 (181/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 656.6ms\n",
            "video 1/1 (182/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 9 persons, 479.3ms\n",
            "video 1/1 (183/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 461.5ms\n",
            "video 1/1 (184/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 460.2ms\n",
            "video 1/1 (185/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 463.4ms\n",
            "video 1/1 (186/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 460.0ms\n",
            "video 1/1 (187/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 12 persons, 464.5ms\n",
            "video 1/1 (188/188) /content/pexels-pixabay-855565-1920x1080-24fps.mp4: 640x640 10 persons, 465.2ms\n",
            "Speed: 0.9ms pre-process, 505.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}